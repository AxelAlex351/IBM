{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#**Maestría en Inteligencia Artificial Aplicada**\n",
        "##**Curso: Inteligencia Artificial y Aprendizaje Automático**\n",
        "###Tecnológico de Monterrey\n",
        "###Prof Luis Eduardo Falcón Morales\n",
        "\n",
        "### **Semana 3**\n",
        "####**Regresión Logística y métodos de Regularización $L_1$ (lasso), $L_2$ (ridge) y el conjunto $L_{12}$ (elastic net).**"
      ],
      "metadata": {
        "id": "DrfZNe792WGZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Parte - 1: Entendiendo los métodos de Regularización con las métricas $L_1$ y $L_2$.**"
      ],
      "metadata": {
        "id": "6k-IEniS2oJt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hay que recordar que en general los métodos de aprendizaje automático supervisado tratan de modelar y explicar el comportamiento de una variable de respuesta $y$, a partir de un conjunto de factores de entrada $X$, dado un conjunto de parejas ordenadas $(\\vec{x}_k, y_k), k=1,2,...,m$. \n",
        "\n",
        "El buen desempeño del modelo se medirá mediante una función de costo que nos permita minimizar el error hasta un mínimo que se considere aceptable por parte del analista. La función de costo puede ser muy variada y los investigadores siguen proponiendo algunas nuevas, pero en particular veamos el caso del método de regresión lineal en detalle para poder ilustrar el problema que nos incumbe en esta semana, el de la **regularización**. Supongamos que el problema es de regresión lineal con dos factores de entrada $x_1$ y $x_2$ y que después del proceso de entrenamiento obtuvimos el modelo $\\hat{y} = \\omega_0 + \\omega_1x_1 + \\omega_2x_2$. A los parámetros $\\omega_j$ se les conoce también como los **pesos** del modelo. Una manera de medir el error de predicción $\\hat{y}_k$ es medir la diferencia o residuo con el valor real observado $y_k$ a través del error cuadrático medio $MSE$ que se define como sigue:\n",
        "\n",
        "$MSE =\\frac{1}{m}\\sum_{k=1}^{m}(\\hat{y}_k-y_k)^2= \\frac{1}{m}\\sum_{k=1}^{m}(\\omega_0+\\omega_1x_{1,k}+\\omega_2x_{2,k}-y_k)^2$\n",
        "\n",
        "donde $x_{j,k}$ indica el factor $x_j$ evaluado en el $k$-ésimo registro. Viendo a $MSE$ como una función de los pesos del modelo, se le suele tomar como la función de costo que se debe minimizar en el conocido método de mínimos cuadrados para el modelo de regresión lineal múltiple. \n",
        "\n",
        "En el caso idealizado de que todas las predicciones del modelo entrenado sean exactamente iguales a las reales observadas, $MSE=0$. Sin embargo, en los problemas reales y por el ruido inherente existente en cada problema, dicho error raramente es identicamente igual a cero. \n",
        "\n",
        "Por otro lado, sabemos que cuando el modelo empieza a sobreentrenarse durante la etapa de entrenamiento, una de las consecuencias es que los coeficientes $\\omega_0$, $\\omega_1$, $\\omega_2$ empiezan a crecer en magnitud. Es por ello que \"regularizar\" el modelo, significa restringirlo para evitar que dichos coeficientes aumenten de manera indiscriminada. Y las dos maneras principales de restringir el crecimiento sin control de dichos pesos, es decir, de regularizar el modelo es mediante las llamadas métricas $L_1$ y $L_2$, como sigue:\n",
        "\n",
        "\n",
        "**Función de costo con métrica de regularización $L_1$. Conocida también como lasso (least absolute shrinkage and selection operator, por sus iniciales en inglés):**\n",
        "\n",
        "$J_{L_1}(\\omega) = MSE + α\\sum_{j=1}^{m}|\\omega_j|$\n",
        "\n",
        "**Función de costo con métrica de regularización $L_2$. También conocida como de Tíjonov (en inglés se le conoce como ridge):**\n",
        "\n",
        "$J_{L_2}(\\omega) = MSE + α\\sum_{j=1}^{m}\\omega_j^2$\n",
        "\n",
        "\n",
        "**Se pueden combinar ambas en la llamada regularización \"elastic net\":**\n",
        "\n",
        "\n",
        "$J_{L_{12}}(\\omega) = MSE + α_1\\sum_{j=1}^{m}|\\omega_j| + α_2\\sum_{j=1}^{m}\\omega_j^2$\n",
        "\n",
        "En español es usual referirse a estos métodos de regularización por el uso de la métrica $L1$, $L_2$ y $L_{12}$ correspondiente, o bien, haciendo referencia a ella por sus nombres en inglés, lasso, ridge y elastic-net, respectivamente.\n",
        "\n",
        "Los parámetros de regularización $\\alpha$, $\\alpha_1$ y $\\alpha_2$ deben ser mayores a cero. El caso igual a cero reduce la función de costo nuevamente a $MSE$.\n",
        "\n",
        "Es importante hacer las siguientes observaciones: \n",
        "\n",
        "*   En cualquiera de los métodos de regularización el parámetro $\\omega_0$ no interviene. Es decir, en el caso del método de regresión lineal, solo se regularizan los coeficientes de cada factor de entrada.\n",
        "\n",
        "*   El sumar los pesos $\\omega_j, j=1,...,m$ a la función de costo en la forma indicada en cada caso, permitirá que el proceso de entrenamiento \"impida\" el crecimiento de los mismos, ya que se está bajo un método de minimización de los errores. \n",
        "\n",
        "*   De manera general, con la métrica $L_2$ se castiga a todos los pesos del modelo de manera uniforme y mientras mayor sea el valor de alguno de los coeficientes, mayor es la penalización para todos.\n",
        "\n",
        "*   De manera general, con la métrica $L_1$, lo factores que el modelo considera que no aportan información para explicar el comportamiento de la variable de salida, los nulifica. Igualmente penaliza a todos los coeficientes(aunque no de manera uniforme), el que alguno de ellos incremente demasiado su valor.\n",
        "\n",
        "*   Aunque las tres técnicas de regularización tienen el mismo objetivo, el impedir que los pesos crezcan demasiado, cada uno tiene sus propias particularidades como lo veremos en un ejemplo sencillo a continuación.\n",
        "\n"
      ],
      "metadata": {
        "id": "Vt0vuFBK4OTt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####**NOTA-Opcional**: Para saber más del tema, puedes consultar la sección llamada \"Regularized Linear Models\" del capítulo 4 del libro de Aurélien Géron.\n"
      ],
      "metadata": {
        "id": "TKbxj1QSzfYH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "xWB_pwwgblWM"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.linear_model import LinearRegression, Lasso, Ridge, ElasticNet"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Definiremos una matriz de entrada X con 3 factores, donde la segunda y tercera son el cuadrado y cubo de la primera. \n",
        "\n",
        "La variable de salida será una función cúbica que las relaciona.\n",
        "\n",
        "Recuerda consultar la documentación de cada función utilizada. Por ejemplo, para las primeras líneas de código:\n",
        "\n",
        "https://numpy.org/doc/stable/reference/generated/numpy.arange.html\n",
        "\n",
        "https://numpy.org/doc/stable/reference/generated/numpy.concatenate.html\n",
        "\n",
        "https://numpy.org/doc/stable/reference/generated/numpy.vstack.html \n"
      ],
      "metadata": {
        "id": "2D6mXnrA5_x5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Definimos nuestras 3 variables en el intervalo -1.3 a 3.5 como sigue:\n",
        "\n",
        "x1 = np.arange(-1.3, 3.5, .125)     # factor/variable lineal\n",
        "x2 = x1*x1                          # factor cuadrático\n",
        "x3 = x1*x1*x1                       # factor cúbico"
      ],
      "metadata": {
        "id": "8U41vHS7cR3G"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Y definimos nuestra matriz de datos de entrada X como un DataFrame de Pandas:\n",
        "# La matriz X estará formada por las columnas 1, 2 y 3 con los factores lineal,\n",
        "# cuadrático y cúbico, respectivamente:\n",
        "\n",
        "w = np.concatenate((np.vstack(x1),np.vstack(x2),np.vstack(x3)), axis=1)\n",
        "w.shape\n",
        "\n",
        "X = pd.DataFrame(w, columns=['x1','x2','x3'])\n",
        "X.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "AgwS8Gfdc4Vm",
        "outputId": "0b9e6d1e-8f35-481a-c973-da915fd7d52b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      x1        x2        x3\n",
              "0 -1.300  1.690000 -2.197000\n",
              "1 -1.175  1.380625 -1.622234\n",
              "2 -1.050  1.102500 -1.157625\n",
              "3 -0.925  0.855625 -0.791453\n",
              "4 -0.800  0.640000 -0.512000"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3957a218-1ebb-443b-a000-52fb01fb50d8\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>x1</th>\n",
              "      <th>x2</th>\n",
              "      <th>x3</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-1.300</td>\n",
              "      <td>1.690000</td>\n",
              "      <td>-2.197000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-1.175</td>\n",
              "      <td>1.380625</td>\n",
              "      <td>-1.622234</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-1.050</td>\n",
              "      <td>1.102500</td>\n",
              "      <td>-1.157625</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-0.925</td>\n",
              "      <td>0.855625</td>\n",
              "      <td>-0.791453</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-0.800</td>\n",
              "      <td>0.640000</td>\n",
              "      <td>-0.512000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3957a218-1ebb-443b-a000-52fb01fb50d8')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-3957a218-1ebb-443b-a000-52fb01fb50d8 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-3957a218-1ebb-443b-a000-52fb01fb50d8');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Definimos los siguientes pesos de manera arbitraria y que establece una relación\n",
        "# polinomial cúbica en nuestra variable de salida Y:\n",
        "\n",
        "w0 = 190\n",
        "w1= -85/3\n",
        "w2=-165\n",
        "w3=160/3\n",
        "\n",
        "print('Pesos (coeficientes) de una función polinomial de grado cúbico como función de salida:')\n",
        "print('lineal: %.2f, cuadrático: %.2f cubo: %.2f' % (w1, w2, w3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bA86cWYgn69N",
        "outputId": "eb46d7f4-0ebb-420f-81e3-78af696c86db"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pesos (coeficientes) de una función polinomial de grado cúbico como función de salida:\n",
            "lineal: -28.33, cuadrático: -165.00 cubo: 53.33\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "En particular por el momento no nos interesa el valor de $\\omega_0$, que equivale el coeficiente constante de la función polinomial. \n",
        "\n",
        "Lo que deseamos es ver el comportamiento de los pesos que se estarán regularizando, que en este caso serán $\\omega_1, \\omega_2$ y $\\omega_3$."
      ],
      "metadata": {
        "id": "4PofWJQlBMip"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Definimos nuestra variable de salida con algo de ruido para que nuestro problema\n",
        "# no se reduzca simplemente a un problema de interpolación de puntos:\n",
        "\n",
        "random.seed(1)\n",
        "yreal = []\n",
        "for x in x1:\n",
        "  noise=200*(random.random() -0.5)\n",
        "  cc = w3*np.power(x,3) + w2*np.power(x,2) + w1*x + w0 + noise\n",
        "  yreal.append(cc)\n",
        "  \n",
        "  \n",
        "plt.scatter(x1,yreal)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "sHKE9NXofki0",
        "outputId": "0dc96c39-ebe2-4218-de2f-1384b4aaaf28"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ya tenemos nuestros datos de salida \"yreal\" a partir de los cuales generar nuestro modelo."
      ],
      "metadata": {
        "id": "d55ntqRypuaG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Recuerda revisar la documentación de cada uno de los modelos que aplicaremos:\n",
        "\n",
        "https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html\n",
        "\n",
        "https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Lasso.html\n",
        "\n",
        "https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Ridge.html\n",
        "\n",
        "https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.ElasticNet.html"
      ],
      "metadata": {
        "id": "6T-OPQjU_5qS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Definamos 4 modelos: el de regresión lineal múltiple (RLM); de RLM con \n",
        "# regularización L1 (lasso); de RLM con regularización L2 (ridge) y\n",
        "# RLM con regularización conjunta L1 y L2 (elastic-net):  \n",
        "\n",
        "modelos = []\n",
        "modelos.append(('LR', LinearRegression()))\n",
        "modelos.append(('LASSO', Lasso(alpha=30)))  \n",
        "modelos.append(('RIDGE', Ridge(alpha=30)))  \n",
        "modelos.append(('EN', ElasticNet(alpha=1, l1_ratio=.5)))\n",
        "\n",
        "\n",
        "yhat0 = []   # predicciones del modelo RLM\n",
        "yhat1 = []   # predicciones del RLM con regularización L1\n",
        "yhat2 = []   # predicciones del RLM con regularización L2\n",
        "yhat12 = []  # predicciones del RLM con regularización L1 y L2\n",
        "\n",
        "\n",
        "for name, model in modelos:\n",
        "  # entrenamos el modelo seleccionado y obtenemos sus predicciones:\n",
        "  print(\"%s:\" % name)\n",
        "  mm = model.fit(X, np.ravel(yreal))\n",
        "  yhat = mm.predict(X)\n",
        "  \n",
        "  print(mm.intercept_)   # por si deseas conocer w0.\n",
        "  print(mm.coef_)       # despleguemos los pesos obtenidos\n",
        "\n",
        "  if name=='LR':\n",
        "    yhat0.append(yhat)\n",
        "    print('\\n')\n",
        "  elif name=='LASSO':\n",
        "    yhat1.append(yhat)\n",
        "    print('\\n')\n",
        "  elif name=='RIDGE':\n",
        "    yhat2.append(yhat)\n",
        "    print('\\n')\n",
        "  else:\n",
        "    yhat12.append(yhat)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SXMyy09Ykjnn",
        "outputId": "a9befc84-60fa-4507-c768-3ed710481fbf"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LR:\n",
            "194.91638384474888\n",
            "[ -40.14979812 -179.70350006   58.72754395]\n",
            "\n",
            "\n",
            "LASSO:\n",
            "117.13069427863499\n",
            "[  -0.         -102.25253563   31.42721669]\n",
            "\n",
            "\n",
            "RIDGE:\n",
            "88.97294849574072\n",
            "[-27.51573296 -61.84734688  22.38804271]\n",
            "\n",
            "\n",
            "EN:\n",
            "105.48167999947967\n",
            "[-32.10655264 -79.34645456  28.06434904]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Algunas comentarios que podemos observar de los resultados anteriores:\n",
        "\n",
        "*   Cuando el parámetro alpha en cualquiera de los modelos con regularización es igual o muy cercano a cero, el resultado será muy parecido al de regresión lineal estándar, LR, lo cual se sigue de las definiciones que dimos al inicio de cada función de costo.\n",
        "\n",
        "*   Cuando el valor de alpha crece en cualquiera de los modelos de regularización, los pesos disminuyen (ya que tratan de minimizar la función de costo). \n",
        "\n",
        "*   Cuando alpha aumenta su valor en el caso Lasso, $L_1$, algunos de los pesos empiezan a tender cero. De hecho, si se sigue aumentando el valor de alpha y en cada caso entrenamos de nuevo el modelo, más pesos seguirán tendiendo a cero. Por ejemplo, modifica y observa los resultados de Lasso para los casos de alpha=0.1, 20, 30 y 65. Es decir, podemos decir que en lasso, algunos de los pesos que el modelo no considera muy relevantes, los castiga más haciéndolos tender a cero.\n",
        "\n",
        "*   La característica anterior del caso lasso, hace que se utilice en ocasiones como reducción de dimensionalidad, es decir, para reducir el conjunto de factores de entrada que tratan de explicar el comportamiento de la variable de salida. O bien, para determinar aquellos factores que dan mayor información a las predicciones. En este caso observamos que el último peso que queda en Lasso con alpha=65 es precisamente el cúbico, dicéndonos que el comportamiento primordial de los datos es cúbico, lo cual sabemos que este es el caso, ya que así los generamos.\n",
        "\n",
        "*   La característica del caso ridge, $L_2$, es que a diferencia de lasso, ahora al aumentar el valor de alpha, todos los pesos serán análogamente penalizados, haciéndolos tender todos a cero pero sin anular alguno de ellos de manera rápida antes que los demás. Por ejemplo, asigna los mismos valores de alpha usados en lasso ahora en ridge e inclusive agrega otros como 100 o 1000 y observa que a diferencia de lo que vimos con lasso, en ridge no se hace exactamente cero uno de los pesos antes que los demás.\n",
        "\n",
        "NOTA: Aunque sabemos que en la vida real los datos no se comportan como en este ejercicio, el ejercicio nos ayuda a entender sus comportamientos generales.\n"
      ],
      "metadata": {
        "id": "3gqTkTtLDOOT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Visualicemos algunos de los resultados**"
      ],
      "metadata": {
        "id": "xdFdFM9yrrQf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.scatter(x1, np.ravel(yreal), marker='^', label='real')  \n",
        "\n",
        "plt.scatter(x1, np.ravel(yhat0), marker='_', label='LR')  \n",
        "plt.scatter(x1, np.ravel(yhat1), marker='o', label='lasso')  \n",
        "plt.scatter(x1, np.ravel(yhat2), marker='d', label='ridge')  \n",
        "plt.scatter(x1, np.ravel(yhat12), marker='*', label='e-net')\n",
        "\n",
        "plt.legend(loc=2)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "cPnwzMlytwTQ",
        "outputId": "ac8a88f0-1116-4bb0-e034-314a6be54222"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Del gráfico anterior, del caso con $\\alpha=30$ en lasso y ridge, podemos hacer algunas observaciones generales:\n",
        "\n",
        "*   En general el modelo sin regularización tiende a querer parecerse lo más rápido posible a los datos reales observados. Si existe una gran cantidad de valores extremos (outliers), esto aumentará la varianza de las predicciones generadas con el modelo obtenido.\n",
        "*   El modelo con las predicciones más cercanas a los datos observados reales tiene los coeficientes mayores en magnitud.\n",
        "*   Observamos que las predicciones del modelo lasso siguen siendo bastante análogas a las de ridge y elastic-net, aún cuando uno de sus coeficientes es igual a cero. Como se mencionó previamente, lasso trata de reducir la cantidad de factores de entrada o dimensionalidad, quedándose con las más representativas y sin sacrificar demasiado el desempeño del modelo.\n",
        "*   Los modelos con regularización generan modelos más \"moderados\" que posteriormente permiten obtener mejores predicciones para los valores reales nuevos, sobre todo cuando existe una buena cantidad de valores extremos (outliers). En este ejemplo en particular que no tenemos valores extremos muy marcados, vemos que los métodos con regularización penalizaron demasiado a todos estos modelos de manera negativa, ya que se alejaron demasiado de los valores reales. \n",
        "\n"
      ],
      "metadata": {
        "id": "5VJ9wghar_f5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Parte - 2: Caso aprobación de tarjetas de crédito** "
      ],
      "metadata": {
        "id": "mCfyqfF2yCYN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "La asignación o rechazo a la solicitud de un crédito a un banco o institución financiera es uno de los problemas más estudiados por su complejidad y relevancia. Existe una gran cantidad de artículos de investigación al respecto. Debido a lo delicado de la información que ahí se analiza no es fácil encontrar bases de datos abiertas con las cuales se puedan estar realizando estudios. Sin embargo, en particular el conjunto de datos conocido como \"Australian credit approval\" es una de las pocas en el tema y que podemos encontrar en el repositorio de la UCI en la siguiente liga:\n",
        "\n",
        "https://archive.ics.uci.edu/ml/datasets/Statlog+%28Australian+Credit+Approval%29\n",
        "\n",
        "El objetivo es determinar si se autoriza una tarjeta de crédito dada cierta información del solicitante.\n",
        "\n",
        "Revisa la información que se encuentra en la página anterior para que tengas mayor información sobre la naturaleza de los datos y del problema. \n"
      ],
      "metadata": {
        "id": "IlOMZhdJvJ59"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns \n",
        "import matplotlib.pyplot as plt \n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold"
      ],
      "metadata": {
        "id": "vN-DVyD6rLtb"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mypath = \"https://archive.ics.uci.edu/ml/machine-learning-databases/statlog/australian/australian.dat\"\n",
        "\n",
        "data = pd.read_csv(mypath, sep=\" \", header=None)\n",
        "\n",
        "data.columns = ['A1','A2','A3','A4','A5','A6','A7','A8','A9','A10','A11','A12','A13','A14','class']\n",
        "\n",
        "print(data.shape)\n",
        "data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 223
        },
        "id": "dUXCreKYy_pD",
        "outputId": "9ea30f79-ac66-4fd4-d756-1f69f1e3d61c"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(690, 15)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   A1     A2     A3  A4  A5  A6     A7  A8  A9  A10  A11  A12  A13   A14  \\\n",
              "0   1  22.08  11.46   2   4   4  1.585   0   0    0    1    2  100  1213   \n",
              "1   0  22.67   7.00   2   8   4  0.165   0   0    0    0    2  160     1   \n",
              "2   0  29.58   1.75   1   4   4  1.250   0   0    0    1    2  280     1   \n",
              "3   0  21.67  11.50   1   5   3  0.000   1   1   11    1    2    0     1   \n",
              "4   1  20.17   8.17   2   6   4  1.960   1   1   14    0    2   60   159   \n",
              "\n",
              "   class  \n",
              "0      0  \n",
              "1      0  \n",
              "2      0  \n",
              "3      1  \n",
              "4      1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-765b3da3-6756-4c4e-b137-bbc2e8056283\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>A1</th>\n",
              "      <th>A2</th>\n",
              "      <th>A3</th>\n",
              "      <th>A4</th>\n",
              "      <th>A5</th>\n",
              "      <th>A6</th>\n",
              "      <th>A7</th>\n",
              "      <th>A8</th>\n",
              "      <th>A9</th>\n",
              "      <th>A10</th>\n",
              "      <th>A11</th>\n",
              "      <th>A12</th>\n",
              "      <th>A13</th>\n",
              "      <th>A14</th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>22.08</td>\n",
              "      <td>11.46</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>1.585</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>100</td>\n",
              "      <td>1213</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>22.67</td>\n",
              "      <td>7.00</td>\n",
              "      <td>2</td>\n",
              "      <td>8</td>\n",
              "      <td>4</td>\n",
              "      <td>0.165</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>160</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>29.58</td>\n",
              "      <td>1.75</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>1.250</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>280</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>21.67</td>\n",
              "      <td>11.50</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>0.000</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>11</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>20.17</td>\n",
              "      <td>8.17</td>\n",
              "      <td>2</td>\n",
              "      <td>6</td>\n",
              "      <td>4</td>\n",
              "      <td>1.960</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>14</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>60</td>\n",
              "      <td>159</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-765b3da3-6756-4c4e-b137-bbc2e8056283')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-765b3da3-6756-4c4e-b137-bbc2e8056283 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-765b3da3-6756-4c4e-b137-bbc2e8056283');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Variables Categóricas y Numéricas**\n",
        "\n",
        "Los nombres de las variables fueron eliminados para cuidar la privacidad de los solicitantes, sin embargo se informa que de las 14 variables de entrada, 8 son categóricas y 6 numéricas.  \n",
        "\n",
        "La última columna es la variable binaria de salida que nos dice si la tarjeta de crédito se autorizó (1) o no se autorizó (0).\n",
        "\n",
        "De acuerdo a la información de la página de la UCI las siguientes 8 variables de entrada son las categóricas:\n",
        "\n",
        "A1 (binaria), A4 (3 niveles), A5 (14 niveles), A6 (9 niveles), A8 (binaria), A9 (binaria), A11 (binaria), A12 (3 niveles).\n",
        "\n",
        "El resto de las 6 variables de entrada las definen como numéricas continuas: \n",
        "\n",
        "A2,  A3,  A7,  A10,  A13,  A14.\n",
        "\n",
        "Con el fin de simplificar el análisis de preparación de los datos adelantamos que varios de los niveles de las variables categóricas tienen muy bajas frecuencias. Algunos tienen por ejemplo 1 solo registro, lo cual hace imposible el querer inferir algo sobre dicho nivel. Por ello agruparemos a continuación algunos de los niveles más bajos bajo el criterio de que al menos cada nivel en cada factor tenga al menos un 5% de información. Existen varias reglas empíricas sobre esta cantidad mínima en cada nivel y la del 5% es una de las más comunes, así que es la que seguiremos en este ejemplo. \n",
        "\n",
        "Aplicaremos la transformación map() de Python para llevar a cabo la agrupación de los niveles de menor frecuencia indicadas mediante un diccionario. En la notación a:b, el entero \"a\" es sustituido por \"b\", como se indica a continuación. \n",
        "\n",
        "Estaremos asignando y agrupando a un mismo nivel 0 a todos aquellos niveles de baja frecuencia.\n",
        "\n"
      ],
      "metadata": {
        "id": "qqvSevM6zRUU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Por ejemplo, veamos cómo se distribuyen los niveles en el caso del factor A4:\n",
        "\n",
        "data['A4'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pYVv41cZPZ9f",
        "outputId": "7f5a7603-9f26-44d9-ceee-3d1b2e6318f8"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2    525\n",
              "1    163\n",
              "3      2\n",
              "Name: A4, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lleva a cabo la inspección de los demás factores categóricos:"
      ],
      "metadata": {
        "id": "HTr1p8_IQLjI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data['A4'] = data['A4'].map({2:2, 1:0, 3:0})\n",
        "data['A5'] = data['A5'].map({1:1,2:0,3:3,4:4,5:0,6:6,7:7,8:8,9:9,10:0,11:11,12:0,13:13,14:14})\n",
        "data['A6'] = data['A6'].map({1:1,2:0,3:0,4:4,5:5,7:0,8:8,9:0})"
      ],
      "metadata": {
        "id": "J_Amy2UA4sjL"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ahora sí, definamos nuestras variables de entrada y de salida, observa que ambas son DataFrames de Pandas:\n",
        "\n",
        "X = data.iloc[:,:-1]  \n",
        "\n",
        "Y = data.iloc[:,-1]     # También puede ser: data[['class']]     "
      ],
      "metadata": {
        "id": "ftMxtlhy78RI"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Consideraremos un $20\\%$ de datos en el conjunto de prueba y dejaremos el resto, $80\\%$, para utilizar en validación-cruzada."
      ],
      "metadata": {
        "id": "GR1GCB2Ra-lV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Xtv, Xtest, ytv, ytest = train_test_split(X, Y, test_size=0.2, stratify=Y, random_state=1)  \n",
        "\n",
        "print(Xtv.shape, ': dimensión de datos de entrada para entrenamiento y validación')\n",
        "print(Xtest.shape, ': dimensión de datos de entrada para prueba')  \n",
        "\n",
        "print(ytv.shape, ': dimensión de variable de salida para entrenamiento y validación')\n",
        "print(ytest.shape, ': dimensión de variable de salida para prueba')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HJ2lIDs68bc_",
        "outputId": "48e6c238-b3fc-4cc3-c751-ca8c21f1580b"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(552, 14) : dimensión de datos de entrada para entrenamiento y validación\n",
            "(138, 14) : dimensión de datos de entrada para prueba\n",
            "(552,) : dimensión de variable de salida para entrenamiento y validación\n",
            "(138,) : dimensión de variable de salida para prueba\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "El argumento \"stratify=Y\" permite generar las particiones conservando el mismo porcentaje de cada clase en cada subconjunto. Otra manera de interpretar el uso de este argumento es decir que la distribución de las clases del conjunto de entrenamiento utilizado para generar el modelo, será la misma que la distribución de las clases que tendrán los datos en la vida real.   \n",
        "\n",
        "Solo para verificar que no estamos con un problema de clases desbalanceadas, problema que abordaremos en semanas más adelante, obtengamos el porcentaje de datos en cada clase de la variable de salida. Esto lo podemos obtener sumando los casos positivos (1) y dividéndolos por el total de registros:\n",
        "\n"
      ],
      "metadata": {
        "id": "4P-78VYsORNF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ytv.sum() / ytv.shape[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RPBJWyNENsj-",
        "outputId": "becb16f2-276e-42ed-c4a3-c9c332fe0811"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.44565217391304346"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tenemos así que las clases de créditos aprobados (1) y no aprobados (0) están distribuidos en un $44.5\\%$ y $55.5\\%$, respectivamente. Esto nos dice que podemos considerarlo como un problema de clases balanceadas, que para el caso biclase teóricamente debe ser del $50\\%$ cada uno.\n",
        "\n",
        "**NOTA:** Habrás observado que en este último paso utilizamos información de los datos de validación junto con los de entrenamiento, e inclusive al utilizar el argumento \"stratify=Y\" en la función \"train_test_split\", estamos utilizando también información de todo el conjunto de datos de la variable de salida para determinar el porcentaje de cada clase, lo cual estricamente lleva a un problema de filtración de información. Sin embargo, tomando en cuenta que las particiones son aleatorizadas, podemos simplificar los procesos y suponer que los porcentajes en cada caso serán relativamente muy parecidos. Además, como vamos a utilizar validación-cruzada, lo cual modifica en cada partición los conjuntos de entrenamiento y validación, habría que calcular el porcentaje de cada clase en cada partición solamente usando los datos de entrenamiento y luego promediarlos, es lo correcto, pero en general no se hace así ya que las diferencias son despreciables si se hace de manera aleatorizada. Aquí es donde también entra el criterio de un buen científico de datos para saber tomar decisiones que aunque a veces no son cien por ciento como dice la teoría, son lo suficientemente acertadas para saber que las diferencias obtenidas son despreciables. "
      ],
      "metadata": {
        "id": "UTqExGzkdJJf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Transformaciones a factores numéricos de entrada:\n",
        "num_pipeline = Pipeline(steps = [('impMediana', SimpleImputer(strategy='median')),\n",
        "                                 ('escalaNum', MinMaxScaler(feature_range=(1,2)))])   \n",
        "num_pipeline_nombres = ['A2','A3','A7','A10','A13','A14']\n",
        "\n",
        "# Transformaciones a factores categóricos de entrada:\n",
        "catImp_pipeline = Pipeline(steps = [('impModa', SimpleImputer(strategy='most_frequent'))])  \n",
        "catImp_pipeline_nombres = ['A1', 'A4', 'A5', 'A6', 'A8', 'A9', 'A11', 'A12']\n",
        "\n",
        "catOHE_pipeline = Pipeline(steps = [('OneHotE', OneHotEncoder(drop='first'))])\n",
        "catOHE_pipeline_nombres = [ 'A4','A5','A6','A12']\n",
        "\n",
        "\n",
        "# Conjuntamos las transformaciones numéricas y categóricas que se estarán aplicando a los datos de entrada:\n",
        "columnasTransformer = ColumnTransformer(transformers = [('numpipe', num_pipeline, num_pipeline_nombres),\n",
        "                                                        ('catimp', catImp_pipeline, catImp_pipeline_nombres),\n",
        "                                                        ('catohe', catOHE_pipeline, catOHE_pipeline_nombres)],\n",
        "                                        remainder='passthrough')"
      ],
      "metadata": {
        "id": "HMY7jcEi97BX"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Más adelante estaremos estudiando los modelos que se muestran a continuación. Por el momento veámoslos simplemente como métodos de aprendizaje supervisado los cuales estamos comparando para ver cuál nos ayuda a predecir mejor la autorización o no de las tarjetas de crédito.\n",
        "\n",
        "Observa que estaremos concatenando los modelos y sus nombres en dos listas diferentes, para posteriormente llevar a cabo el entrenamiento de cada uno de ellos de manera secuensial. \n",
        "\n",
        "Recuerda que una manera general de empezar a abordar un problema en el área de aprendizaje automático es partiendo del entrenamiento de varios modelos diferentes con sus valores de agrumentos predeterminados para una primera comparación. Sin embargo, con el fin de evitar errores posteriores de no convergencia estamos modificando ligeramente algunos de ellos como se muestran a continuación. \n",
        "\n",
        "Puedes ir revisando la documentación de cada uno de estos métodos en scikit-learn. "
      ],
      "metadata": {
        "id": "uPazkO0WAPH1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_models():\n",
        "  modelos = list()\n",
        "  nombres = list()\n",
        "\n",
        "  # LR - Regresión Logística:\n",
        "  modelos.append(LogisticRegression(solver='liblinear'))\n",
        "  nombres.append('LR')\n",
        "\n",
        "  # DT - Árbol de Decisión:\n",
        "  modelos.append(DecisionTreeClassifier())\n",
        "  nombres.append('DT')\n",
        "  \n",
        "  # MLP - Red Neuronal Artificial / Perceptrón Lineal Multicapa:  \n",
        "  modelos.append(MLPClassifier(hidden_layer_sizes=(30,), max_iter=3000))\n",
        "  nombres.append('MLP')\n",
        "  \n",
        "  # SVM - Máquina de Vector Soporte:\n",
        "  modelos.append(SVC(gamma='scale'))\n",
        "  nombres.append('SVM')\n",
        "\n",
        "  # kNN - k-Vecinos más cercanos:\n",
        "  modelos.append(KNeighborsClassifier())\n",
        "  nombres.append('kNN')\n",
        "  \n",
        "  return modelos, nombres"
      ],
      "metadata": {
        "id": "YTj86cd3_l_r"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Llevamos a cabo el entrenamiento usando el Pipeline para la transformación de los datos y que nos ayuda a evitar el filtrado de información de los datos entre los conjuntos de validación y prueba. \n",
        "\n",
        "Usaremos validación-cruzada (cross-validation, CV) con su variante de repetir el proceso además varias veces (nosotros lo haremos 3 veces) y donde las particiones se generan estratificadas, para respetar en lo posible la distribución de las clases en cada partición del CV. Revisa la siguiente liga de su documentación:\n",
        "\n",
        "https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RepeatedStratifiedKFold.html"
      ],
      "metadata": {
        "id": "IooOOrPXIIWk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "modelos, nombres = get_models()  # cargamos los modelos a comparar\n",
        "resultados = list()   \n",
        "\n",
        "for i in range(len(modelos)):\n",
        "\n",
        "  pipeline = Pipeline(steps=[('ct',columnasTransformer),('m',modelos[i])])\n",
        "\n",
        "  cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=0)\n",
        "  scores = cross_val_score(pipeline, Xtv, np.ravel(ytv), scoring='accuracy', cv=cv)\n",
        "\n",
        "\n",
        "  resultados.append(scores)\n",
        "  print('>> %s: %.3f (%.3f)' % (nombres[i], np.mean(scores), np.std(scores)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nWaZ-tc3DXPE",
        "outputId": "a6e92f27-80c6-4b2d-872d-8628713af559"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ">> LR: 0.861 (0.039)\n",
            ">> DT: 0.818 (0.058)\n",
            ">> MLP: 0.840 (0.038)\n",
            ">> SVM: 0.850 (0.041)\n",
            ">> kNN: 0.791 (0.040)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Observamos que el modelo de regresión logística es el obtiene el mejor desempeño promedio con respecto a la métrica de exactitud (accuracy). Entre paréntesis se muestra la desviación estándar de cada resultado.\n",
        "\n",
        "Mostremos también sus diagramas de caja y bigotes para visualizar mejor la variabilidad de cada resultado:"
      ],
      "metadata": {
        "id": "0PWWAsPvJrrK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.boxplot(resultados, labels=nombres, showmeans=True)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "eSMdq9PPeIzc",
        "outputId": "b0f9f040-85af-4400-9e2b-baf6aa14c512"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Regresión Logística con regularizaciones $L_1$ y $L_2$:**\n",
        "\n",
        "Ya que la regresión logística fue la de mejor desempeño en cuanto a promedio en el entrenamiento anterior, realicemos un nuevo entrenamiento aplicando ahora las técnicas de regularización. Lo haremos de manera análoga a como procedimos anteriormente. Sin embargo, ahora usaremos los argumentos de la función LogisticRegression de scikit-learn para implementar cada uno de los casos de regularización. Esto simplemente para mostrar las diversas formas que en general se puede llegar a implementar un mismo proceso. Posiblemente no se obtenga exactamente el mismo resultado usando ambos casos, pero se esperaría que fueran aproximadamente análogos.\n",
        "\n",
        "En este caso debes revisar la documentación para ver cuáles argumentos son adecuados en cada método de regularización ya que no todas las combinaciones son posibles, generando errores de ejecución en algunas de ellas. Para evitarlo revisa la liga de la documentación correspondiente:\n",
        "\n",
        "https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html \n",
        "\n",
        "Y nuevamente se han modificado algunos de los valores predeterminados en algunos de ellos para que cada uno converja durante el proceso de entrenamiento."
      ],
      "metadata": {
        "id": "Fe87BYvvJ355"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#from pandas.core.common import random_state\n",
        "\n",
        "def get_modelsRegs():\n",
        "  modelos, nombres = list(), list()\n",
        "\n",
        "  # LR - sin regularización:\n",
        "  modelos.append(LogisticRegression(penalty='none', solver='lbfgs', max_iter=2000, random_state=1))\n",
        "  nombres.append('LR')\n",
        "\n",
        "  # Lasso:\n",
        "  modelos.append(LogisticRegression(penalty='l1', solver='liblinear', max_iter=2000, C=1., random_state=1))\n",
        "  nombres.append('LASSO')\n",
        "  \n",
        "  # Ridge:\n",
        "  modelos.append(LogisticRegression(penalty='l2', solver='liblinear', max_iter=2000, C=10.01, random_state=1))\n",
        "  nombres.append('RIDGE')\n",
        "  \n",
        "  # Elastic-Net:\n",
        "  modelos.append(LogisticRegression(penalty='elasticnet', l1_ratio=0.5, solver='saga', max_iter=4000, C=1., random_state=1))\n",
        "  nombres.append('EN')\n",
        "\n",
        "  return modelos, nombres"
      ],
      "metadata": {
        "id": "wEaQEjEiK_Kz"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "modelos, nombres = get_modelsRegs()\n",
        "resultados = list() \n",
        "\n",
        "for i in range(len(modelos)):\n",
        "\n",
        "  pipeline = Pipeline(steps=[('ct',columnasTransformer),('m',modelos[i])])\n",
        "\n",
        "  cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=5, random_state=8)\n",
        "  scores = cross_val_score(pipeline, Xtv, np.ravel(ytv), scoring='accuracy', cv=cv)\n",
        "\n",
        "  resultados.append(scores)\n",
        "  print('>> %s %.3f (%.3f)' % (nombres[i], np.mean(scores), np.std(scores)))\n",
        "\n",
        "\n",
        "plt.boxplot(resultados, labels=nombres, showmeans=True)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 334
        },
        "id": "QvTCiEfkMdle",
        "outputId": "2e01bba5-fa2c-437b-e2b4-23ba08b0008b"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ">> LR 0.868 (0.050)\n",
            ">> LASSO 0.867 (0.046)\n",
            ">> RIDGE 0.869 (0.048)\n",
            ">> EN 0.863 (0.048)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Actividad-comentario en Canvas:**\n",
        "\n",
        "###**Con base a la exactitud y desviación estándar de cada modelo mostrados en los resultados anteriores, ¿qué puedes decir del modelo generado? ¿Ayudan en este caso el uso de las técnicas de regularización para obtener un mejor modelo? ¿Podríamos considerar las diferencias mostradas entre ellos suficientes como para hablar de que uno de ellos es mejor que los otros?** \n",
        "\n",
        "###**Realiza ajustes a los argumentos de algunos de los modelos y observa si puedes obtener un mejor resultado, al menos en cuanto a su promedio general.**\n",
        "\n",
        "###**¿Qué podrías concluir al respecto?**\n",
        "\n",
        "###**¿Se obtuvo un un buen ajuste en alguno de los modelos?**\n",
        "\n",
        "###**¿Están subentrenados?**\n",
        "\n",
        "###**¿Están sobreentrenados?**\n",
        "\n",
        "###**¿Qué otra información necesitarías para responder estas preguntas?**"
      ],
      "metadata": {
        "id": "D7pRZOwgNKNj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Llevando a cabo el mejor ajuste (fine tuning)**\n",
        "\n",
        "Observamos que aunque de manera mínima se obtuvo que el modelo de regresión logística con regularización ridge $L_2$ fue el más alto, así que a manera de ejemplo continuemos con el ejercicio para mostrar la manera de encontrar una mejor configuración de los hiperparámetros mediante la llamada búsqueda por malla (grid search en inglés). \n",
        "\n",
        "Recuerda revisar la documentación correspondiente cada vez que uses un nuevo método o función, en particular revisa las siguientes dos que utilizaremos a continuación:\n",
        "\n",
        "https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html\n",
        "\n",
        "https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html"
      ],
      "metadata": {
        "id": "_8uZ9wJgNUwb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import confusion_matrix"
      ],
      "metadata": {
        "id": "1ktA40R3NqUZ"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Podemos realizar una búsqueda con varias opciones de los valores de algunos de los hiperparámetros y acelerar el proceso de búsqueda mediante el uso de las funciones llamados de malla, que probarán un conjunto de combinaciones durante un mismo proceso de entrenamiento. Si se tienen los recursos computacionales adecuados este timpo de entrenamiento puede ser paralelizable.\n",
        "\n",
        "Las diferentes opciones para cada parámetro seleccionado se indican a través de un diccionario. Los diccionarios son un tipo muy importante de estructura para colecciones de datos en un formato dado como \"clave:valor\". Si no conoces los diccionarios y no lo has trabajado dentro de Python, te recomendamos revisar primero la siguiente documentación al respecto, antes de seguir adelante:\n",
        "\n",
        "https://docs.python.org/3/tutorial/datastructures.html#dictionaries \n",
        "\n",
        "Ahora utilicemos un diccionario para indicar las diferentes opciones de valores que tomará cada argumento que hemos seleccionado para la función de regresión logística. Observa el formato \"clave:valor\" del diccionario \"dicc_grid\" definido a continuación, donde en particular para el modelo ridge las \"claves\" que estamos considerando son los métodos de optimización, indicados por \"solver\" y la constante \"C\" que rige el nivel de resticción de la métrica $L_2$ que se está aplicando."
      ],
      "metadata": {
        "id": "KJuJSEPzlHkZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# RIDGE - métrica L2:\n",
        "\n",
        "modelo = LogisticRegression(penalty='l2', max_iter=10000, random_state=1)\n",
        "\n",
        "dicc_grid = {'C':[0.0001,0.01,0.1,1.0,10.,100.],\n",
        "             'solver':['newton-cg','lbfgs','liblinear','sag','saga']\n",
        "             }\n",
        "\n",
        "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=5, random_state=8)\n",
        "\n",
        "grid = GridSearchCV(estimator=modelo, \n",
        "                    param_grid=dicc_grid, \n",
        "                    cv=cv, \n",
        "                    scoring='accuracy')\n"
      ],
      "metadata": {
        "id": "a-7Ma4XIhMmr"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Transformamos los datos de entrada:\n",
        "Xx = columnasTransformer.fit_transform(Xtv)\n",
        "\n",
        "# Llevamos a cabo el proceso de etrenamiento con validación-cruzada y búsqueda de malla.\n",
        "# Observa que de acuerdo a las opciones incluidas en la malla, se estarán realizando (6)(5)=30 \n",
        "# combinaciones diferentes, además de las (10)(5)=50 particiones de la validación-cruzada,\n",
        "# lo cual implica también un mayor tiempo de entrenamiento.\n",
        "\n",
        "grid.fit(Xx, np.ravel(ytv))\n",
        "\n",
        "print('Mejor valor de exactitud obtenido con la mejor combinación:', grid.best_score_)\n",
        "print('Mejor combinación de valores encontrados de los hiperparámetros:', grid.best_params_)\n",
        "print('Métrica utilizada:', grid.scoring)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r-1p6YMahMiu",
        "outputId": "390a92f3-2cfb-4db2-c311-2298abd5a75d"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mejor valor de exactitud obtenido con la mejor combinación: 0.8695389610389609\n",
            "Mejor combinación de valores encontrados de los hiperparámetros: {'C': 100.0, 'solver': 'liblinear'}\n",
            "Métrica utilizada: accuracy\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Obtenemos una mejoría mínima de aproximadamente un $0.05\\%$ en cuanto al promedio general de la exactitud, en relación con el valor de la regularización ridge que habíamos obtenido previamente.\n",
        "\n",
        "Puedes intentar modificar los valores de estos hiperparámetros alrededor de estos valores encontrados para ver si puedes incrementar aún más dicho valor promedio. En particular se podrían intentar valores alrededor de C=100."
      ],
      "metadata": {
        "id": "6yEeLwpQk2Gh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Modelo Final con el conjunto de prueba y conclusiones**\n",
        "\n",
        "Finalmente obtuvimos que una de las mejores configuraciones fue la regresión logística con el método de regularización $L_2$. Habría que evaluar si realmente consideramos que dicha diferencia obtenida es suficientemente mayor a la del modelo de regresión lineal sin regularización y con los parámetros predeterminados, o bien aplicar el criterio de la navaja de Ockham y quedarnos con el modelo más simple. Aunque en un challenge como los que propone Kaggle dicha diferencia mínima sería suficiente para determinar un ganador y por lo tanto valdría la pena realizar dicho ajuste.\n",
        "\n",
        "Con base a nuestro ejemplo ilustrativo, continuemos finalmente con los hiperparámetros encontrados para el mejor resultado de regularización con métrica $L_2$ encontrado, a saber, regresión logística con regularización ridge y valores de C=100.0, solver=liblinear.\n",
        "\n",
        "Para ello usemos por último el conjunto de prueba, que hasta ahora no habíamos utilizado."
      ],
      "metadata": {
        "id": "oHKIKQxmOZsr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "modelo = LogisticRegression(penalty='l2', \n",
        "                            max_iter=10000,\n",
        "                            C=100.0,\n",
        "                            solver='liblinear',\n",
        "                            random_state=1)\n",
        "\n",
        "# Entrenamos el modelo por última vez con los datos de entrenamiento y validación conjuntos:\n",
        "Xct = columnasTransformer.fit(Xtv)\n",
        "Xxt = Xct.transform(Xtv)\n",
        "modelo.fit(Xxt, np.ravel(ytv))\n",
        "\n",
        "# Transformamos los datos de prueba y los utilizamos por primera vez para obtener sus predicciones\n",
        "# y desempeño del modelo:\n",
        "\n",
        "Xxtest = Xct.transform(Xtest)\n",
        "print(modelo.score(Xxtest, np.ravel(ytest)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l3gmzhamjaEa",
        "outputId": "8e8eec96-d683-4814-8c79-f554c4562bdf"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8405797101449275\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Así, finalmente podemos decir que el desempeño promedio de nuestro modelo será del $84.06\\%$ cuando se utilice en producción con los nuevos datos reales. \n",
        "\n",
        "En realidad antes de llevarlo a producción debemos verificar que el modelo no esté subentrenado o sobreentrenado. De hecho esta pregunta te la hicimos anteriormente, pero volveremos a abordar este tema con estos mismos datos la semana entrante.\n",
        "\n",
        "Por último veamos la manera en que nuestro modelo final lleva a cabo las prediciones de cada clase, se autoriza o no la tarjeta de crédito, mediante el uso de la llamada matriz de confusión: "
      ],
      "metadata": {
        "id": "FELDvX061NS8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pp = modelo.predict(Xxtest)\n",
        "cm = confusion_matrix(ytest, pp)\n",
        "print(cm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PbjecfL31BFJ",
        "outputId": "149a5eb6-808e-47b6-c05b-9a7f94a72e49"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[61 16]\n",
            " [ 6 55]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "La matriz de confusión nos ayuda a visualizar la manera en que nuestro modelo está llevando a cabo las predicciones, es decir, la manera en que realiza predicciones correctas o incorrectas.\n",
        "\n",
        "\n",
        "###**Para entender el concepto de la matriz de confusión, realiza la lectura de la subsección \"Confusion Matrix\" del capítulo 3, \"Classification\", sección \"Performance Measures\" del libro de Aurélien Géron.**\n",
        "\n",
        "Igualmente puedes consultar la documentación de scikit-learn sobre el mismo tema:\n",
        "\n",
        "https://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html#sphx-glr-auto-examples-model-selection-plot-confusion-matrix-py"
      ],
      "metadata": {
        "id": "QEHn6eECnL77"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se puede obtener una mejor visualización de la matriz de confusión mediante las siguientes instrucciones con la librería seaborn. \n",
        "\n",
        "Ver la documentación correspondiente:\n",
        "\n",
        "https://seaborn.pydata.org/generated/seaborn.heatmap.html\n",
        "\n"
      ],
      "metadata": {
        "id": "cqu0uf68yfKM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "txt = ['Verdaderos Negativos','Falsos Positivos','Falsos Negativos','Verdaderos Positivos']\n",
        "frecuencia = [\"{0:0.0f}\".format(value) for value in cm.flatten()]\n",
        "porcentaje = [\"{0:.1%}\".format(value) for value in cm.flatten()/np.sum(cm)]\n",
        "\n",
        "labels = [f\"{v1}\\n{v2}\\n{v3}\" for v1, v2, v3 in zip(txt,frecuencia,porcentaje)]\n",
        "labels = np.asarray(labels).reshape(2,2)\n",
        "\n",
        "ax = sns.heatmap(cm, annot=labels, fmt='', cmap='Blues', cbar=False)\n",
        "ax.set(ylabel=\"Etiquetas Reales\", xlabel=\"Etiquetas de Predicción\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 280
        },
        "id": "tvKZXAvFVQ7u",
        "outputId": "36a5d1c2-32ef-4762-9a4d-b7b9f1545566"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "En particular observamos que las predicciones de falsos positivos es mayor que la de falsos negativos. ¿Crees que esto sea lo mejor? Es decir, qué resultaría más costoso para el banco ¿autorizar una tarjeta de crédito a un mal cliente (falso positivo), o negársela a un buen cliente (falso negativo)? ¿Qué información adicional necestitarías para contestar adecuadamente estas preguntas?"
      ],
      "metadata": {
        "id": "K5UYJfQGimnM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**--Fin de la actividad--**"
      ],
      "metadata": {
        "id": "Ry-kKwoMyWxQ"
      }
    }
  ]
}